---
  title: "Lasso with Tidymodels"
output:
  html_document:
  number_sections: true
fig_caption: true
fig_width: 5
fig_height: 4
theme: cosmo
highlight: tango
code_folding: show
---
  
  ```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.align = "center")
```

```{r load_lib, message=FALSE, warning=FALSE, results='hide'}
library(tidymodels) # 모델링
library(tidyverse) # 전처리
library(magrittr) # Pipe operator
library(skimr) # 데이터 체크용
library(knitr) # RMD 작성
library(naniar) # NA 확인
library(plyr)
library(gridExtra)
```

# Data load

```{r}
file_path <- "../input/house-prices-advanced-regression-techniques/"
files <- list.files(file_path)
files
```

```{r, message=FALSE}
train <- read_csv(file.path(file_path, "train.csv"))
test <- read_csv(file.path(file_path, "test.csv"))
```


# Data Preprocessing

저는 기본적으로 janitor를 사용하지 않았습니다. 메타데이터를 보면서 처리하기에는 오히려 원본 데이터를 그대로 사용하는 편이 더 편하기 때문입니다.

## `all_data` 전처리

```{r}
# bind train test
all_data <- 
  bind_rows(train, test) %>%
  select(-c(Id))
# %>% 
# mutate(
#   MSSubClass = as.factor(MSSubClass), # MSSubClass는 범주형 변수이므로 factor로 변환
#   OverallQual = factor(OverallQual, order = T, levels = c(1,2,3,4,5,6,7,8,9,10)),
#   OverallCond = factor(OverallCond, order = T, levels = c(1,2,3,4,5,6,7,8,9,10))
# )
```

- `mutate_if`를 사용하여 모두 Factor로 변환하려고 했으나, Imputation 영역에서 치환할 시 문자열이 입력이 안되는 경우가 발생하여 Chractor로 자료형을 그대로 두었습니다.

```{r}
skim(all_data)
```

# EDA


## SalePrice의 분포

전체적인 SalePrice의 분포를 보겠습니다.

```{r}
all_data %>% filter(!is.na(SalePrice)) %>% 
  summarise(mean = mean(SalePrice), # 180921
            medain = median(SalePrice)) # 163000


all_data %>% filter(!is.na(SalePrice)) %>% 
  ggplot(aes(x = SalePrice))+
  geom_histogram(fill = 'blue', binwidth = 10000) +
  scale_x_continuous(breaks = seq(0,800000, by = 100000), label = comma)+
  geom_vline(aes(xintercept = 163000), lty = 2, col = 'red') # median
```
- 오른쪽으로 Skewed 되어있는 데이터입니다. 정규성을 위해서 로그를 취하는 게 필요해 보입니다.
- 비싸게 팔린 집들이 좀 있네요. 나중에 데이터를 정리할 때 염두해두도록 하겠습니다.

## Correlation

먼저 모든 숫자열 변수들을 골라냅니다.
```{r}
numVars <- which(sapply(all_data, is.numeric))
numVarNames <- names(numVars)
length(numVars)
```
- `which`함수는 해당하는 데이터 컬럼의 순서를 반환합니다.
- `sapply`는 데이터를 받아 matrix나 vector로 반환합니다.
- 그래서 sapply를 통해 벡터화된 데이터가 which를 통해 컬럼순서를 반환하게 됩니다.

```{r}
library(corrplot)
all_numVar <- all_data[, numVars]
cor_numVar <- cor(all_numVar, use="pairwise.complete.obs") #correlations of all numeric variables

#sort on decreasing correlations with SalePrice
cor_sorted <- as.matrix(sort(cor_numVar[,'SalePrice'], decreasing = TRUE))
#select only high corelations
CorHigh <- names(which(apply(cor_sorted, 1, function(x) abs(x)>0.5)))
cor_numVar <- cor_numVar[CorHigh, CorHigh]

corrplot.mixed(cor_numVar, tl.col="black", tl.pos = "lt", number.cex = 0.75)

```

- **cor_numVar**에 `cor`함수를 적용하면 matrix로 자료형이 변환됩니다. 그래서 뒤이어 이어지는 모든 데이터 정렬이 matrix로써 이루어지므로 R 본연의 함수를 많이 사용하게 되네요.
- **SalePrice**기준으로 데이터를 내림차순 정렬 후 다시 메트릭스로 변환합니다.
- 그리고 `apply` 에서 **1**은 row를 의미합니다. 2가 되면 열을 기준으로 적용되겠네요. 그렇게 상관계수가 0.5가 넘는 항목들만 남게 됩니다.
- **공분산성**이 보입니다. GarageArea와 GarageCar은 0.89로 거의 1에 가까운 공분산성을 띄네요.


## GrLivArea
앞으로 이 컬럼을 '지상 면적'이라고 하겠습니다. 지상면적을 시각화 해봅시다. 이렇게 지상면적을 시각화하는 이유는, 가겨과 가장 높은 correlation을 형성하기 때문에 특이한 사항이 있는지 확인하기 위해서입니다.

```{r}
library(ggrepel) # ggplot에서 label을 도와주는 라이브러리
all_data %>% filter(!is.na(SalePrice)) %>% 
  ggplot(aes(x = GrLivArea, y = SalePrice))+
  geom_point() +
  geom_smooth(method = 'lm', se = F) +
  scale_y_continuous(breaks = seq(0,800000, by = 100000), label = comma)+
  geom_text_repel(aes(label = ifelse(all_data$GrLivArea[!is.na(all_data$SalePrice)]>4500, rownames(all_data), '')))
```
- `geom_repel`은 Scatter Plot에서 데이터 포인트를 지정해주는 좋은 라이브러리입니다.
- 두 개의 Outlier가 보입니다. 각각 524, 1299번째 행에 있는 데이터이군요. 나중에 Outlier를 정리할 때 함께 고려하는 게 좋아보입니다.


## Imputation  {.tabset .tabset-fade}

Data에 NA가 들어있으면 머신러닝이 제대로 동작하지 않습니다. 그렇기 때문에 NA를 적절히 제거해주는 게 정말로 중요합니다. 하지만 아무렇게나 제거할 수 없기에 Imputation 과정을 반드시 거쳐야 합니다.


```{r message=FALSE, class.source = 'fold-hide'}
all_data %>% 
  select(where(~sum(is.na(.)) > 0)) %>% 
  gg_miss_var()
```

-`naniar`라이브러리를 사용한 NA 데이터 시각화입니다.


### PoolQC
처음에 데이터를 봤을 때는 NA는 잘못된 값인 줄 알고 해당 컬럼을 데이터에서 제외하고 시작했습니다. 하지만 잘못된 생각이었더라고요. NA는 입력하지 않은 데이터가 아니라 **풀장이 없는** 데이터였습니다. 꼼꼼히 데이터를 살피지 않으면 중요한 정보를 날릴 수도 있다는 중요한 교훈을 얻었습니다 :)

PoolQC: Pool quality

Ex	Excellent
Gd	Good
TA	Average/Typical
Fa	Fair
NA	No Pool

```{r}
all_data$PoolQC[is.na(all_data$PoolQC)] <- 'None'

Quality <- c('None'=0 ,'Po' = 1, 'Fa' = 2, 'TA' = 3, 'Gd' = 4, 'Ex' = 5)
all_data$PoolQC <- as.integer(revalue(all_data$PoolQC, Quality))

table(all_data$PoolQC)

# all_data[all_data$PoolQC == 0 & all_data$PoolArea >0, c("PoolArea", "PoolQC","OverallQual")]

```
- **PoolQC**가 NA인 값들을 None으로 바꿔줍니다.
- Quality Vector를 만들어서 모두 nominal variable을 ordinal variable로 만들 준비를 합니다.
- `plyr` 함수인 `revalue`를 통해서 모든 ordinal variable로 변경한 뒤, 다시 integer로 만들어줍니다.

### MiscFeature

MiscFeature: Miscellaneous feature not covered in other categories

Elev	Elevator
Gar2	2nd Garage (if not described in garage section)
Othr	Other
Shed	Shed (over 100 SF)
TenC	Tennis Court
NA	None

```{r}
all_data$MiscFeature[is.na(all_data$MiscFeature)] <- 'None'
all_data <- 
  all_data %>% 
  mutate(MiscFeature = as.factor(MiscFeature))

table(all_data$MiscFeature)

a <- all_data %>% filter(!is.na(SalePrice)) %>% 
  ggplot(aes(x = MiscFeature, y = SalePrice))+
  geom_bar(stat = 'summary', fun = 'mean', fill = 'blue', alpha = 0.7)+
  scale_y_continuous(breaks= seq(0, 800000, by=100000), labels = comma) +
  geom_label(stat = "count", aes(label = ..count.., y = ..count..))

b <- all_data %>% filter(!is.na(SalePrice)) %>% 
  ggplot(aes(x = MiscFeature, y = SalePrice))+
  geom_bar(stat = 'summary', fun = 'median', fill = 'blue', alpha = 0.7)

grid.arrange(a,b)

```

### Alley

Alley: Type of alley access to property

Grvl	Gravel
Pave	Paved
NA 	No alley access

```{r}
all_data$Alley[is.na(all_data$Alley)] <- 'None'
all_data <- 
  all_data %>% 
  mutate(Alley = as.factor(Alley))

ggplot(all_data[!is.na(all_data$SalePrice),], aes(x=Alley, y=SalePrice)) +
  geom_bar(stat='summary', fun = "median", fill='blue')+
  scale_y_continuous(breaks= seq(0, 200000, by=50000), labels = comma)

```


### Fence

Fence: Fence quality

GdPrv	Good Privacy
MnPrv	Minimum Privacy
GdWo	Good Wood
MnWw	Minimum Wood/Wire
NA	No Fence

```{r}
all_data$Fence[is.na(all_data$Fence)] <- 'None'
all_data <- 
  all_data %>% 
  mutate(Fence = as.factor(Fence))

```


### Fireplace

FireplaceQu: Fireplace quality

Ex	Excellent - Exceptional Masonry Fireplace
Gd	Good - Masonry Fireplace in main level
TA	Average - Prefabricated Fireplace in main living area or Masonry Fireplace in basement
Fa	Fair - Prefabricated Fireplace in basement
Po	Poor - Ben Franklin Stove
NA	No Fireplace

```{r}
all_data$FireplaceQu[is.na(all_data$FireplaceQu)] <- 'None'

all_data$FireplaceQu <- as.integer(revalue(all_data$FireplaceQu, Quality))
table(all_data$FireplaceQu)

```
### Lot Variables

LotFrontage: Linear feet of street connected to property

```{r}

ggplot(all_data[!is.na(all_data$SalePrice),], aes(x=as.factor(Neighborhood), y=LotFrontage)) +
  geom_bar(stat='summary', fun = "median", fill='blue')+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```
- LotFrontage는 Lot와 Main Road까지의 거리이므로 **Neighborhood** 별로 median 값을 취해서 imputation 해주는 게 좋아보입니다.


```{r}
for (i in 1:nrow(all_data)){
  if(is.na(all_data$LotFrontage[i])){
    all_data$LotFrontage[i] <- median(all_data$LotFrontage[all_data$Neighborhood == all_data$Neighborhood[[i]]],na.rm = T)
  }
}

sum(is.na((all_data$LotFrontage)))
```

- for문을 이용하여 Neighborhood의 median에 맡게 imputation을 진행했습니다.
- tidyverse로 쉽게 할 수 있는 방법이 있으면 좋겠네요 ~_~
  
  이쯤에서 중간점검을 해봅시다.
```{r}
sort(colSums(is.na(all_data)), decreasing = T)
```
- 아직 많이 남았네요. 단 Garage와 Basement가 주된 Imputation의 대상이 될 것 같습니다.
- 나머지 50개 이하의 Value에 대해서는 `recipe`단계에서 간단히 처리하고 모델로 넘어가야 할 것 같습니다.

### Garage Vars
차고 변수에는 GarageYrBlt, GarageFinish, GarageQual, GarageCond, GarageType가 있고 157~ 159개의 NA값이 들어있습니다.

```{r}
all_data %>% 
  select(c(GarageYrBlt, GarageFinish, GarageQual, GarageCond, GarageType,GarageCars,GarageArea, YearBuilt)) %>% 
  filter(is.na(GarageYrBlt)|is.na(GarageFinish)|is.na(GarageQual)|is.na(GarageCond)|is.na(GarageType)) %>% 
  filter(!is.na(GarageType) & is.na(GarageFinish))
```
- 2개의 변수 중에 하나는 차고가 있고 하나는 차고가 없지만 GarageType이 실수로 입력된 것 같군요.
- 첫 번째 값은 최빈값으로 정리를 해주도록 합시다.

```{r}
which(all_data$GarageType == 'Detchd' & is.na(all_data$GarageCond)) #2127, 2577
all_data$GarageFinish[2127] <- names(sort(table(all_data$GarageFinish), decreasing = T))[1]
all_data$GarageQual[2127] <- names(sort(table(all_data$GarageQual), decreasing = T))[1]
all_data$GarageCond[2127] <- names(sort(table(all_data$GarageCond), decreasing = T))[1]
```


#### GarageYrBlt
차고가 만들어진 날짜는 보통 건물이 지어진 일자일 확률이 높으니 건물이 지어진 날짜로 넣어줍시다.

```{r}
all_data <- all_data %>% 
  mutate(GarageYrBlt = ifelse(is.na(GarageYrBlt),YearBuilt,GarageYrBlt))
```

#### GarageFinish

GarageFinish: Interior finish of the garage

Fin	Finished
RFn	Rough Finished	
Unf	Unfinished
NA	No Garage

```{r}
all_data$GarageFinish[is.na(all_data$GarageFinish)] <- 'None'
```


#### GarageQual

GarageQual: Garage quality

Ex	Excellent
Gd	Good
TA	Typical/Average
Fa	Fair
Po	Poor
NA	No Garage

```{r}
all_data$GarageQual[is.na(all_data$GarageQual)] <- 'None'
all_data$GarageQual <- as.integer(revalue(all_data$GarageQual,Quality))
```


#### GarageCond

GarageCond: Garage condition

Ex	Excellent
Gd	Good
TA	Typical/Average
Fa	Fair
Po	Poor
NA	No Garage		

```{r}
all_data$GarageCond[is.na(all_data$GarageCond)] <- 'None'
all_data$GarageCond <- as.integer(revalue(all_data$GarageCond,Quality))
```


#### GarageType

GarageType: Garage location

2Types	More than one type of garage
Attchd	Attached to home
Basment	Basement Garage
BuiltIn	Built-In (Garage part of house - typically has room above garage)
CarPort	Car Port
Detchd	Detached from home
NA	No Garage

```{r}
all_data$GarageType[is.na(all_data$GarageType)] <- 'None'
```

#### GarageCars & GarageArea

GarageCars: Size of garage in car capacity

GarageArea: Size of garage in square feet




# 4. validation split
```{r}
set.seed(234)
val_set <- validation_split(train, 
                            prop = 0.80)
val_set
```






## Imputation

### KNN Imputation 
```{r}
recipe_house <- 
  recipe(SalePrice ~ ., data = all_data ) %>%
  step_impute_knn(all_predictors(), neighbors = 3)

recipe_house2 <- prep(recipe_house, training = train)
imputed <- bake(recipe_house2, new_data = NULL)
```


### impute 결과
```{r}
imputed %>% 
  skim()
```

# Preprecessing with `recipe` (전처리 레시피 만들기)

## Make recipe

```{r}
housing_recipe <- all_data %>% 
  recipe(SalePrice ~ .) %>%
  step_log(SalePrice) %>% 
  step_impute_knn(all_predictors(), neighbors = 3) %>% 
  step_dummy(all_nominal()) %>% 
  step_zv(all_predictors()) %>% 
  step_normalize(all_predictors())

print(housing_recipe)
```

## Juice and split again
```{r}
all_data2 <- 
  housing_recipe %>% 
  prep() %>% 
  juice()

#split again
train_index <- seq_len(nrow(train))
train <- all_data2[train_index,]
test <- all_data2[-train_index,]
```



## Make Model

```{r message=FALSE, warning=FALSE}
lasso_mod <- 
  linear_reg(penalty = 0.01, mixture = 1) %>% # lasso: 1, ridge: 0
  set_engine("glmnet")

lasso_fit <- 
  lasso_mod %>% 
  fit(SalePrice ~ ., data = train)

```


## Predict

```{r}
result <- predict(lasso_fit, test)

```

```{r}
submission <- read_csv(file.path(file_path, "sample_submission.csv"))
submission$SalePrice <- exp(result$.pred)
write.csv(submission, row.names = FALSE,
          "lasso_regression_with_Feature_En.csv")
```
